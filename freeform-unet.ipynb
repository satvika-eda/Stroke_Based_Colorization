{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-21T20:00:28.032837Z",
     "iopub.status.busy": "2025-04-21T20:00:28.032626Z",
     "iopub.status.idle": "2025-04-21T20:12:45.038266Z",
     "shell.execute_reply": "2025-04-21T20:12:45.037684Z",
     "shell.execute_reply.started": "2025-04-21T20:00:28.032819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "\n",
    "imagenet_train_dir = \"/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train\"\n",
    "# Path to new subset directory\n",
    "subset_dir = \"/kaggle/working/imagenet_subset/train\"\n",
    "\n",
    "# Number of classes and images per class\n",
    "num_classes = 50\n",
    "images_per_class = 1000\n",
    "\n",
    "# Get list of all class folders\n",
    "all_classes = sorted(os.listdir(imagenet_train_dir))\n",
    "# Choose 50 classes (randomly or specify your own)\n",
    "selected_classes = random.sample(all_classes, num_classes)\n",
    "\n",
    "os.makedirs(subset_dir, exist_ok=True)\n",
    "\n",
    "for class_name in selected_classes:\n",
    "    src_class_dir = os.path.join(imagenet_train_dir, class_name)\n",
    "    dst_class_dir = os.path.join(subset_dir, class_name)\n",
    "    os.makedirs(dst_class_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all images in this class\n",
    "    images = sorted(os.listdir(src_class_dir))\n",
    "    # Select up to 1000 images\n",
    "    selected_images = images[:images_per_class]\n",
    "    \n",
    "    for img_name in selected_images:\n",
    "        src_img_path = os.path.join(src_class_dir, img_name)\n",
    "        dst_img_path = os.path.join(dst_class_dir, img_name)\n",
    "        shutil.copyfile(src_img_path, dst_img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:12:45.039708Z",
     "iopub.status.busy": "2025-04-21T20:12:45.039473Z",
     "iopub.status.idle": "2025-04-21T20:12:48.757066Z",
     "shell.execute_reply": "2025-04-21T20:12:48.756503Z",
     "shell.execute_reply.started": "2025-04-21T20:12:45.039690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader# from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class ImageNetColorizationDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_paths = []\n",
    "        for subdir, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.JPEG') or file.endswith('.jpg'):\n",
    "                    self.image_paths.append(os.path.join(subdir, file))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\").resize((256, 256))\n",
    "            img = np.array(img)\n",
    "    \n",
    "            lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "            L = lab[:, :, 0] / 255.0\n",
    "            ab = lab[:, :, 1:] / 128.0\n",
    "    \n",
    "            L = torch.from_numpy(L).unsqueeze(0).float()        # [1, H, W]\n",
    "            ab = torch.from_numpy(ab.transpose((2, 0, 1))).float()  # [2, H, W]\n",
    "    \n",
    "            return L, ab\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {img_path}: {e}\")\n",
    "            return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:12:48.758066Z",
     "iopub.status.busy": "2025-04-21T20:12:48.757729Z",
     "iopub.status.idle": "2025-04-21T20:12:53.549361Z",
     "shell.execute_reply": "2025-04-21T20:12:53.548645Z",
     "shell.execute_reply.started": "2025-04-21T20:12:48.758043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "imagenet_dataset = ImageNetColorizationDataset('/kaggle/working/imagenet_subset/train', transform=transform)\n",
    "train_loader = DataLoader(\n",
    "    imagenet_dataset,\n",
    "    batch_size=32,                  # Increase batch size if memory allows\n",
    "    shuffle=True,\n",
    "    num_workers=8,                  # Increase workers (rule: 4 * num_GPUs)\n",
    "    pin_memory=True,                # Keep this for GPU transfer efficiency\n",
    "    prefetch_factor=2,              # Prefetch batches\n",
    "    persistent_workers=True,        # Keep workers alive between epochs\n",
    "    drop_last=True                  # Slightly faster by dropping incomplete batches\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:12:53.550839Z",
     "iopub.status.busy": "2025-04-21T20:12:53.550152Z",
     "iopub.status.idle": "2025-04-21T20:12:53.834740Z",
     "shell.execute_reply": "2025-04-21T20:12:53.834187Z",
     "shell.execute_reply.started": "2025-04-21T20:12:53.550794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def rgb_to_lab(img_rgb):\n",
    "    img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
    "    L, a, b = cv2.split(img_lab)\n",
    "    return L / 255.0, a / 128.0, b / 128.0  # normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:59:40.142885Z",
     "iopub.status.busy": "2025-04-24T06:59:40.142570Z",
     "iopub.status.idle": "2025-04-24T06:59:45.173227Z",
     "shell.execute_reply": "2025-04-24T06:59:45.172192Z",
     "shell.execute_reply.started": "2025-04-24T06:59:40.142854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UNetColor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNetColor, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 2, stride=2), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 2, stride=2), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 2, stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(32, 2, 1)  # 2 output channels: a and b\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:12:53.844084Z",
     "iopub.status.busy": "2025-04-21T20:12:53.843832Z",
     "iopub.status.idle": "2025-04-21T20:12:54.104383Z",
     "shell.execute_reply": "2025-04-21T20:12:54.103841Z",
     "shell.execute_reply.started": "2025-04-21T20:12:53.844061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# 1. Define the model\n",
    "model = UNetColor()\n",
    "\n",
    "# 2. Move model to GPU if available (optional but recommended)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 3. Now define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:12:54.105352Z",
     "iopub.status.busy": "2025-04-21T20:12:54.105117Z",
     "iopub.status.idle": "2025-04-21T20:12:54.109720Z",
     "shell.execute_reply": "2025-04-21T20:12:54.109132Z",
     "shell.execute_reply.started": "2025-04-21T20:12:54.105329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def lab_to_rgb(L, a, b):\n",
    "    L = L * 255.0\n",
    "    a = a * 128.0\n",
    "    b = b * 128.0\n",
    "    lab = cv2.merge([L.astype(np.uint8), a.astype(np.uint8), b.astype(np.uint8)])\n",
    "    rgb = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "    return rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:12:54.111026Z",
     "iopub.status.busy": "2025-04-21T20:12:54.110758Z",
     "iopub.status.idle": "2025-04-21T20:47:08.295415Z",
     "shell.execute_reply": "2025-04-21T20:47:08.294350Z",
     "shell.execute_reply.started": "2025-04-21T20:12:54.111003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for L, ab in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        L, ab = L.to(device), ab.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_ab = model(L)\n",
    "        loss = criterion(output_ab, ab)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:49:42.470462Z",
     "iopub.status.busy": "2025-04-21T20:49:42.470193Z",
     "iopub.status.idle": "2025-04-21T20:49:42.482262Z",
     "shell.execute_reply": "2025-04-21T20:49:42.481465Z",
     "shell.execute_reply.started": "2025-04-21T20:49:42.470443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "def visualize_colorization(model, dataloader, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for L, ab in dataloader:\n",
    "            L, ab = L.to(device), ab.to(device)\n",
    "            output_ab = model(L)\n",
    "\n",
    "            # Get first sample in batch\n",
    "            L_img = L[0].cpu().numpy()[0] * 255.0  # [256, 256]\n",
    "            ab_gt = ab[0].cpu().numpy().transpose(1, 2, 0) * 128.0  # [256, 256, 2]\n",
    "            ab_pred = output_ab[0].cpu().numpy().transpose(1, 2, 0) * 128.0\n",
    "\n",
    "            # Construct LAB images\n",
    "            lab_gt = np.zeros((256, 256, 3), dtype=np.float32)\n",
    "            lab_pred = np.zeros((256, 256, 3), dtype=np.float32)\n",
    "            lab_gt[:, :, 0] = L_img\n",
    "            lab_gt[:, :, 1:] = ab_gt\n",
    "            lab_pred[:, :, 0] = L_img\n",
    "            lab_pred[:, :, 1:] = ab_pred\n",
    "\n",
    "            # Convert LAB to RGB\n",
    "            rgb_gt = cv2.cvtColor(lab_gt.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "            rgb_pred = cv2.cvtColor(lab_pred.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "            # Grayscale visualization\n",
    "            gray_img = cv2.cvtColor(rgb_gt, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(rgb_gt)\n",
    "            plt.title(\"Original\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(gray_img, cmap='gray')\n",
    "            plt.title(\"Input Grayscale\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(rgb_pred)\n",
    "            plt.title(\"Reconstructed\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            break  # Show only one batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:49:42.820536Z",
     "iopub.status.busy": "2025-04-21T20:49:42.820252Z",
     "iopub.status.idle": "2025-04-21T20:49:44.968112Z",
     "shell.execute_reply": "2025-04-21T20:49:44.967133Z",
     "shell.execute_reply.started": "2025-04-21T20:49:42.820514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "visualize_colorization(model, train_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:56:25.738627Z",
     "iopub.status.busy": "2025-04-21T20:56:25.738007Z",
     "iopub.status.idle": "2025-04-21T20:56:25.751724Z",
     "shell.execute_reply": "2025-04-21T20:56:25.750943Z",
     "shell.execute_reply.started": "2025-04-21T20:56:25.738604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResNetUNetColor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetUNetColor, self).__init__()\n",
    "\n",
    "        # Load pretrained ResNet18\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "        # Use only first conv block (accepts RGB), we’ll modify to accept 1-channel input\n",
    "        self.input_conv = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Extract ResNet layers for encoder\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "\n",
    "        self.layer1 = resnet.layer1  # [64, 64, 64]\n",
    "        self.layer2 = resnet.layer2  # [128, 32, 32]\n",
    "        self.layer3 = resnet.layer3  # [256, 16, 16]\n",
    "        self.layer4 = resnet.layer4  # [512, 8, 8]\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = self.up_block(512, 256)\n",
    "        self.up2 = self.up_block(512, 128)  # skip from layer3\n",
    "        self.up3 = self.up_block(256, 64)   # skip from layer2\n",
    "        self.up4 = self.up_block(128, 64)   # skip from layer1\n",
    "        self.up5 = nn.Sequential(           # final upsampling to 256×256\n",
    "            nn.ConvTranspose2d(64, 32, 2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 2, kernel_size=1)  # Output ab channels\n",
    "        )\n",
    "\n",
    "    def up_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.relu(self.bn1(self.input_conv(x)))  # [64, 128, 128]\n",
    "        x2 = self.layer1(self.maxpool(x1))            # [64, 64, 64]\n",
    "        x3 = self.layer2(x2)                          # [128, 32, 32]\n",
    "        x4 = self.layer3(x3)                          # [256, 16, 16]\n",
    "        x5 = self.layer4(x4)                          # [512, 8, 8]\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        d1 = self.up1(x5)                             # [256, 16, 16]\n",
    "        d2 = self.up2(torch.cat([d1, x4], dim=1))     # [128, 32, 32]\n",
    "        d3 = self.up3(torch.cat([d2, x3], dim=1))     # [64, 64, 64]\n",
    "        d4 = self.up4(torch.cat([d3, x2], dim=1))     # [64, 128, 128]\n",
    "        out = self.up5(d4)                            # [2, 256, 256]\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:57:09.908676Z",
     "iopub.status.busy": "2025-04-21T20:57:09.907991Z",
     "iopub.status.idle": "2025-04-21T20:57:10.127031Z",
     "shell.execute_reply": "2025-04-21T20:57:10.126467Z",
     "shell.execute_reply.started": "2025-04-21T20:57:09.908654Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model2 = ResNetUNetColor().to(device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model2 = model2.to(device)\n",
    "\n",
    "# 3. Now define the optimizer\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:57:32.735661Z",
     "iopub.status.busy": "2025-04-21T20:57:32.735193Z",
     "iopub.status.idle": "2025-04-21T21:32:16.139908Z",
     "shell.execute_reply": "2025-04-21T21:32:16.139172Z",
     "shell.execute_reply.started": "2025-04-21T20:57:32.735640Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model2.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for L, ab in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        L, ab = L.to(device), ab.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_ab = model2(L)\n",
    "        loss = criterion(output_ab, ab)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T21:40:15.055241Z",
     "iopub.status.busy": "2025-04-21T21:40:15.054552Z",
     "iopub.status.idle": "2025-04-21T21:40:17.231264Z",
     "shell.execute_reply": "2025-04-21T21:40:17.230320Z",
     "shell.execute_reply.started": "2025-04-21T21:40:15.055219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "visualize_colorization(model2, train_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T21:33:12.798852Z",
     "iopub.status.busy": "2025-04-21T21:33:12.798544Z",
     "iopub.status.idle": "2025-04-21T21:33:12.881204Z",
     "shell.execute_reply": "2025-04-21T21:33:12.880660Z",
     "shell.execute_reply.started": "2025-04-21T21:33:12.798832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model2.state_dict(), \"/kaggle/working/resnet_unet_colorization_model_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T21:33:13.407829Z",
     "iopub.status.busy": "2025-04-21T21:33:13.407561Z",
     "iopub.status.idle": "2025-04-21T21:33:13.489210Z",
     "shell.execute_reply": "2025-04-21T21:33:13.488662Z",
     "shell.execute_reply.started": "2025-04-21T21:33:13.407809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/kaggle/working/unet_colorization_model_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T21:41:40.497906Z",
     "iopub.status.busy": "2025-04-21T21:41:40.497324Z",
     "iopub.status.idle": "2025-04-21T21:41:41.071821Z",
     "shell.execute_reply": "2025-04-21T21:41:41.071243Z",
     "shell.execute_reply.started": "2025-04-21T21:41:40.497883Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Load image from URL\n",
    "url = \"https://huggingface.co/takuma104/controlnet_dev/resolve/main/bird_512x512.png\"\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content)).convert(\"RGB\").resize((256, 256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T21:41:48.314164Z",
     "iopub.status.busy": "2025-04-21T21:41:48.313544Z",
     "iopub.status.idle": "2025-04-21T21:41:48.322311Z",
     "shell.execute_reply": "2025-04-21T21:41:48.321615Z",
     "shell.execute_reply.started": "2025-04-21T21:41:48.314142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def colorize_image_from_url(model, url, device):\n",
    "    model.eval()\n",
    "\n",
    "    # Load and resize image\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content)).convert(\"RGB\").resize((256, 256))\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Convert RGB to LAB and extract L\n",
    "    lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "    L = lab[:, :, 0] / 255.0\n",
    "\n",
    "    # Convert to tensor\n",
    "    L_tensor = torch.from_numpy(L).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "    # Predict ab channels\n",
    "    with torch.no_grad():\n",
    "        ab_pred = model(L_tensor)[0].cpu().numpy().transpose(1, 2, 0) * 128.0\n",
    "\n",
    "    # Reconstruct LAB and convert to RGB\n",
    "    lab_pred = np.zeros((256, 256, 3), dtype=np.float32)\n",
    "    lab_pred[:, :, 0] = L * 255.0\n",
    "    lab_pred[:, :, 1:] = ab_pred\n",
    "    rgb_pred = cv2.cvtColor(lab_pred.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Original Input\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(rgb_pred)\n",
    "    plt.title(\"Colorized Output\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T21:42:14.738504Z",
     "iopub.status.busy": "2025-04-21T21:42:14.737813Z",
     "iopub.status.idle": "2025-04-21T21:42:16.564343Z",
     "shell.execute_reply": "2025-04-21T21:42:16.563711Z",
     "shell.execute_reply.started": "2025-04-21T21:42:14.738466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "url = \"https://huggingface.co/takuma104/controlnet_dev/resolve/main/bird_512x512.png\"\n",
    "colorize_image_from_url(model2, url, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T21:43:05.189022Z",
     "iopub.status.busy": "2025-04-21T21:43:05.188335Z",
     "iopub.status.idle": "2025-04-21T21:43:05.196326Z",
     "shell.execute_reply": "2025-04-21T21:43:05.195665Z",
     "shell.execute_reply.started": "2025-04-21T21:43:05.188990Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def colorize_single_image(model, image_path, device):\n",
    "    model.eval()\n",
    "\n",
    "    # Load and resize image\n",
    "    img = Image.open(image_path).convert(\"RGB\").resize((256, 256))\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Convert to LAB and extract L channel\n",
    "    lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "    L = lab[:, :, 0] / 255.0  # Normalize L channel\n",
    "\n",
    "    # Convert to tensor\n",
    "    L_tensor = torch.from_numpy(L).unsqueeze(0).unsqueeze(0).float().to(device)  # [1, 1, 256, 256]\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        ab_pred = model(L_tensor)[0].cpu().numpy().transpose(1, 2, 0) * 128.0\n",
    "\n",
    "    # Reconstruct LAB image and convert to RGB\n",
    "    L_img = L * 255.0\n",
    "    lab_pred = np.zeros((256, 256, 3), dtype=np.float32)\n",
    "    lab_pred[:, :, 0] = L_img\n",
    "    lab_pred[:, :, 1:] = ab_pred\n",
    "    rgb_pred = cv2.cvtColor(lab_pred.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    # Show result\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(rgb_pred)\n",
    "    plt.title(\"Colorized Output\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T21:45:51.485428Z",
     "iopub.status.busy": "2025-04-21T21:45:51.484881Z",
     "iopub.status.idle": "2025-04-21T21:45:51.811521Z",
     "shell.execute_reply": "2025-04-21T21:45:51.810853Z",
     "shell.execute_reply.started": "2025-04-21T21:45:51.485404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/test/ILSVRC2012_test_00000003.JPEG\"  # Upload your own image to input folder\n",
    "colorize_single_image(model2, image_path, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 4225553,
     "sourceId": 6799,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
