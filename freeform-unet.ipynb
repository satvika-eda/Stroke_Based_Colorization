{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Freeform Colorization with U-Net</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satvika Eda, Divya Sri Bandaru & Dhriti Anjaria\n",
    "# 21nd April 2025\n",
    "# This code is for freeform image colorization with U-Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of specific ImageNet class IDs to include in the subset\n",
    "\n",
    "subset_class_ids = [\n",
    "    \"n01440764\", \"n01491361\", \"n01498041\", \"n01514859\", \"n01530575\", \"n01616318\", \"n01622779\", \"n01629819\", \"n01641577\", \"n01664065\",\n",
    "    \"n01729322\", \"n01734418\", \"n01742172\", \"n01774750\", \"n01795545\", \"n01806143\", \"n01833805\", \"n01882714\", \"n01914609\", \"n01945685\",\n",
    "    \"n01978455\", \"n01985128\", \"n02002556\", \"n02006656\", \"n02011460\", \"n02058221\", \"n02071294\", \"n02085782\", \"n02088466\", \"n02099601\",\n",
    "    \"n02100583\", \"n02104029\", \"n02106550\", \"n02110063\", \"n02110958\", \"n02112137\", \"n02113023\", \"n02113799\", \"n02123045\", \"n02128757\",\n",
    "    \"n02132136\", \"n02165456\", \"n02190166\", \"n02206856\", \"n02226429\", \"n02233338\", \"n02256656\", \"n02279972\", \"n02317335\", \"n02346627\",\n",
    "    \"n02364673\", \"n02391049\", \"n02395406\", \"n02403003\", \"n02412080\", \"n02415577\", \"n02423022\", \"n02437312\", \"n02480495\", \"n02504458\",\n",
    "    \"n02509815\", \"n02640242\", \"n02692877\", \"n02708093\", \"n02786058\", \"n02795169\", \"n02814533\", \"n02823428\", \"n02837789\", \"n02879718\",\n",
    "    \"n02951358\", \"n02966193\", \"n03014705\", \"n03047690\", \"n03085013\", \"n03100240\", \"n03126707\", \"n03160309\", \"n03179701\", \"n03255030\",\n",
    "    \"n03272010\", \"n03314780\", \"n03379051\", \"n03417042\", \"n03424325\", \"n03444034\", \"n03478589\", \"n03494278\", \"n03584829\", \"n03633091\",\n",
    "    \"n03666591\", \"n03770439\", \"n03793489\", \"n03814639\", \"n03888257\", \"n03933933\", \"n03976657\", \"n04037443\", \"n04118538\", \"n04552348\"\n",
    "]\n",
    "\n",
    "imagenet_train_dir = \"/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train\"\n",
    "subset_dir = \"/kaggle/working/imagenet_subset/train\"\n",
    "os.makedirs(subset_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through specified class IDs and copy all images\n",
    "for class_id in subset_class_ids:\n",
    "    src_class_dir = os.path.join(imagenet_train_dir, class_id)\n",
    "    dst_class_dir = os.path.join(subset_dir, class_id)\n",
    "    os.makedirs(dst_class_dir, exist_ok=True)\n",
    "    \n",
    "    images = sorted(os.listdir(src_class_dir))\n",
    "    for img_name in images:\n",
    "        src_img_path = os.path.join(src_class_dir, img_name)\n",
    "        dst_img_path = os.path.join(dst_class_dir, img_name)\n",
    "        shutil.copyfile(src_img_path, dst_img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:12:45.039708Z",
     "iopub.status.busy": "2025-04-21T20:12:45.039473Z",
     "iopub.status.idle": "2025-04-21T20:12:48.757066Z",
     "shell.execute_reply": "2025-04-21T20:12:48.756503Z",
     "shell.execute_reply.started": "2025-04-21T20:12:45.039690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset for loading ImageNet images\n",
    "class ImageNetColorizationDataset(Dataset):\n",
    "\n",
    "    # To initialize the dataset by collecting all image file paths\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_paths = []\n",
    "        for subdir, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.JPEG') or file.endswith('.jpg'):\n",
    "                    self.image_paths.append(os.path.join(subdir, file))\n",
    "        self.transform = transform\n",
    "\n",
    "    # To return the total number of images found\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    # To load an image, convert and return the L channel and ab channels as tensors\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\").resize((256, 256))\n",
    "            img = np.array(img)\n",
    "    \n",
    "            lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "            L = lab[:, :, 0] / 255.0\n",
    "            ab = lab[:, :, 1:] / 128.0\n",
    "    \n",
    "            L = torch.from_numpy(L).unsqueeze(0).float()       \n",
    "            ab = torch.from_numpy(ab.transpose((2, 0, 1))).float()  \n",
    "    \n",
    "            return L, ab\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {img_path}: {e}\")\n",
    "            return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:12:48.758066Z",
     "iopub.status.busy": "2025-04-21T20:12:48.757729Z",
     "iopub.status.idle": "2025-04-21T20:12:53.549361Z",
     "shell.execute_reply": "2025-04-21T20:12:53.548645Z",
     "shell.execute_reply.started": "2025-04-21T20:12:48.758043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a DataLoader for the ImageNet colorization dataset\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "imagenet_dataset = ImageNetColorizationDataset('/kaggle/working/imagenet_subset/train', transform=transform)\n",
    "train_loader = DataLoader(\n",
    "    imagenet_dataset,\n",
    "    batch_size=32,                  \n",
    "    shuffle=True,\n",
    "    num_workers=8,                  \n",
    "    pin_memory=True,                \n",
    "    prefetch_factor=2,             \n",
    "    persistent_workers=True,       \n",
    "    drop_last=True                 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:59:40.142885Z",
     "iopub.status.busy": "2025-04-24T06:59:40.142570Z",
     "iopub.status.idle": "2025-04-24T06:59:45.173227Z",
     "shell.execute_reply": "2025-04-24T06:59:45.172192Z",
     "shell.execute_reply.started": "2025-04-24T06:59:40.142854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model for Vanilla UNet Architecture\n",
    "class UNetColor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNetColor, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 2, stride=2), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 2, stride=2), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 2, stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(32, 2, 1)  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:12:53.844084Z",
     "iopub.status.busy": "2025-04-21T20:12:53.843832Z",
     "iopub.status.idle": "2025-04-21T20:12:54.104383Z",
     "shell.execute_reply": "2025-04-21T20:12:54.103841Z",
     "shell.execute_reply.started": "2025-04-21T20:12:53.844061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create model and move to CUDA, using MSE loss and Adam Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "model = UNetColor()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T20:12:54.111026Z",
     "iopub.status.busy": "2025-04-21T20:12:54.110758Z",
     "iopub.status.idle": "2025-04-21T20:47:08.295415Z",
     "shell.execute_reply": "2025-04-21T20:47:08.294350Z",
     "shell.execute_reply.started": "2025-04-21T20:12:54.111003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training section with L and ab\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for L, ab in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        L, ab = L.to(device), ab.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_ab = model(L)\n",
    "        loss = criterion(output_ab, ab)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T21:43:05.189022Z",
     "iopub.status.busy": "2025-04-21T21:43:05.188335Z",
     "iopub.status.idle": "2025-04-21T21:43:05.196326Z",
     "shell.execute_reply": "2025-04-21T21:43:05.195665Z",
     "shell.execute_reply.started": "2025-04-21T21:43:05.188990Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To colorize single image with model in evaluation mode\n",
    "\n",
    "def colorize_single_image(model, image_path, device):\n",
    "    model.eval()\n",
    "\n",
    "    img = Image.open(image_path).convert(\"RGB\").resize((256, 256))\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Convert to LAB and extract L channel\n",
    "    lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "    L = lab[:, :, 0] / 255.0 \n",
    "\n",
    "    L_tensor = torch.from_numpy(L).unsqueeze(0).unsqueeze(0).float().to(device) \n",
    "    with torch.no_grad():\n",
    "        ab_pred = model(L_tensor)[0].cpu().numpy().transpose(1, 2, 0) * 128.0\n",
    "\n",
    "    L_img = L * 255.0\n",
    "    lab_pred = np.zeros((256, 256, 3), dtype=np.float32)\n",
    "    lab_pred[:, :, 0] = L_img\n",
    "    lab_pred[:, :, 1:] = ab_pred\n",
    "    rgb_pred = cv2.cvtColor(lab_pred.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(rgb_pred)\n",
    "    plt.title(\"Colorized Output\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T21:45:51.485428Z",
     "iopub.status.busy": "2025-04-21T21:45:51.484881Z",
     "iopub.status.idle": "2025-04-21T21:45:51.811521Z",
     "shell.execute_reply": "2025-04-21T21:45:51.810853Z",
     "shell.execute_reply.started": "2025-04-21T21:45:51.485404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To test the vanilla model performance on different images\n",
    "\n",
    "image_path = \"/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/test/ILSVRC2012_test_00000003.JPEG\"  # Upload your own image to input folder\n",
    "colorize_single_image(model, image_path, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 4225553,
     "sourceId": 6799,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
