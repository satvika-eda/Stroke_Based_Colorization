{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Freeform Colorization with Hybrid Resnet-UNet</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satvika Eda, Divya Sri Bandaru & Dhriti Anjaria\n",
    "# 20nd April 2025\n",
    "# This code is for freeform image colorization with Hybrid Resnet-UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of specific ImageNet class IDs to include in the subset\n",
    "\n",
    "subset_class_ids = [\n",
    "    \"n01440764\", \"n01491361\", \"n01498041\", \"n01514859\", \"n01530575\", \"n01616318\", \"n01622779\", \"n01629819\", \"n01641577\", \"n01664065\",\n",
    "    \"n01729322\", \"n01734418\", \"n01742172\", \"n01774750\", \"n01795545\", \"n01806143\", \"n01833805\", \"n01882714\", \"n01914609\", \"n01945685\",\n",
    "    \"n01978455\", \"n01985128\", \"n02002556\", \"n02006656\", \"n02011460\", \"n02058221\", \"n02071294\", \"n02085782\", \"n02088466\", \"n02099601\",\n",
    "    \"n02100583\", \"n02104029\", \"n02106550\", \"n02110063\", \"n02110958\", \"n02112137\", \"n02113023\", \"n02113799\", \"n02123045\", \"n02128757\",\n",
    "    \"n02132136\", \"n02165456\", \"n02190166\", \"n02206856\", \"n02226429\", \"n02233338\", \"n02256656\", \"n02279972\", \"n02317335\", \"n02346627\",\n",
    "    \"n02364673\", \"n02391049\", \"n02395406\", \"n02403003\", \"n02412080\", \"n02415577\", \"n02423022\", \"n02437312\", \"n02480495\", \"n02504458\",\n",
    "    \"n02509815\", \"n02640242\", \"n02692877\", \"n02708093\", \"n02786058\", \"n02795169\", \"n02814533\", \"n02823428\", \"n02837789\", \"n02879718\",\n",
    "    \"n02951358\", \"n02966193\", \"n03014705\", \"n03047690\", \"n03085013\", \"n03100240\", \"n03126707\", \"n03160309\", \"n03179701\", \"n03255030\",\n",
    "    \"n03272010\", \"n03314780\", \"n03379051\", \"n03417042\", \"n03424325\", \"n03444034\", \"n03478589\", \"n03494278\", \"n03584829\", \"n03633091\",\n",
    "    \"n03666591\", \"n03770439\", \"n03793489\", \"n03814639\", \"n03888257\", \"n03933933\", \"n03976657\", \"n04037443\", \"n04118538\", \"n04552348\"\n",
    "]\n",
    "\n",
    "imagenet_train_dir = \"/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train\"\n",
    "subset_dir = \"/kaggle/working/imagenet_subset/train\"\n",
    "os.makedirs(subset_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through specified class IDs and copy all images\n",
    "for class_id in subset_class_ids:\n",
    "    src_class_dir = os.path.join(imagenet_train_dir, class_id)\n",
    "    dst_class_dir = os.path.join(subset_dir, class_id)\n",
    "    os.makedirs(dst_class_dir, exist_ok=True)\n",
    "    \n",
    "    images = sorted(os.listdir(src_class_dir))\n",
    "    for img_name in images:\n",
    "        src_img_path = os.path.join(src_class_dir, img_name)\n",
    "        dst_img_path = os.path.join(dst_class_dir, img_name)\n",
    "        shutil.copyfile(src_img_path, dst_img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:55:31.001358Z",
     "iopub.status.busy": "2025-04-23T18:55:31.001106Z",
     "iopub.status.idle": "2025-04-23T18:55:35.140207Z",
     "shell.execute_reply": "2025-04-23T18:55:35.139654Z",
     "shell.execute_reply.started": "2025-04-23T18:55:31.001339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# A Dataset for loading ImageNet images and preparing them for grayscale to LAB colorization tasks\n",
    "\n",
    "class ImageNetColorizationDataset(Dataset):\n",
    "\n",
    "    # To initialize the dataset by collecting all image file paths\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_paths = []\n",
    "        for subdir, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.JPEG') or file.endswith('.jpg'):\n",
    "                    self.image_paths.append(os.path.join(subdir, file))\n",
    "        self.transform = transform\n",
    "\n",
    "    # To return the total number of images found\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    # To load an image, convert and return the L channel and ab channels as tensors\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\").resize((256, 256))\n",
    "            img = np.array(img)\n",
    "    \n",
    "            lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "            L = lab[:, :, 0] / 255.0\n",
    "            ab = lab[:, :, 1:] / 128.0\n",
    "    \n",
    "            L = torch.from_numpy(L).unsqueeze(0).float()        # [1, H, W]\n",
    "            ab = torch.from_numpy(ab.transpose((2, 0, 1))).float()  # [2, H, W]\n",
    "    \n",
    "            return L, ab\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {img_path}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:55:35.141524Z",
     "iopub.status.busy": "2025-04-23T18:55:35.141217Z",
     "iopub.status.idle": "2025-04-23T18:55:39.901677Z",
     "shell.execute_reply": "2025-04-23T18:55:39.900992Z",
     "shell.execute_reply.started": "2025-04-23T18:55:35.141501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a DataLoader for the ImageNet colorization dataset\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "imagenet_dataset = ImageNetColorizationDataset('/kaggle/working/imagenet_subset/train', transform=transform)\n",
    "train_loader = DataLoader(\n",
    "    imagenet_dataset,\n",
    "    batch_size=32,                  \n",
    "    shuffle=True,\n",
    "    num_workers=8,                  \n",
    "    pin_memory=True,                \n",
    "    prefetch_factor=2,              \n",
    "    persistent_workers=True,       \n",
    "    drop_last=True                  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:55:44.587090Z",
     "iopub.status.busy": "2025-04-23T18:55:44.586810Z",
     "iopub.status.idle": "2025-04-23T18:55:44.596206Z",
     "shell.execute_reply": "2025-04-23T18:55:44.595570Z",
     "shell.execute_reply.started": "2025-04-23T18:55:44.587068Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model for Hybrid Resnet UNet Architecture\n",
    "\n",
    "class ResNetUNetColor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetUNetColor, self).__init__()\n",
    "\n",
    "        # Loaded pretrained ResNet18\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        self.input_conv = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Used ResNet layers for encoder\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "\n",
    "        self.layer1 = resnet.layer1 \n",
    "        self.layer2 = resnet.layer2 \n",
    "        self.layer3 = resnet.layer3 \n",
    "        self.layer4 = resnet.layer4 \n",
    "\n",
    "        # Decoder section with skip conenctions\n",
    "        self.up1 = self.up_block(512, 256)\n",
    "        self.up2 = self.up_block(512, 128)  \n",
    "        self.up3 = self.up_block(256, 64)   \n",
    "        self.up4 = self.up_block(128, 64)  \n",
    "        self.up5 = nn.Sequential(           \n",
    "            nn.ConvTranspose2d(64, 32, 2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 2, kernel_size=1)  \n",
    "        )\n",
    "\n",
    "    def up_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.relu(self.bn1(self.input_conv(x)))  \n",
    "        x2 = self.layer1(self.maxpool(x1))           \n",
    "        x3 = self.layer2(x2)                        \n",
    "        x4 = self.layer3(x3)                         \n",
    "        x5 = self.layer4(x4)                         \n",
    "\n",
    "        # Decoder with skip connections\n",
    "        d1 = self.up1(x5)                            \n",
    "        d2 = self.up2(torch.cat([d1, x4], dim=1))    \n",
    "        d3 = self.up3(torch.cat([d2, x3], dim=1))   \n",
    "        d4 = self.up4(torch.cat([d3, x2], dim=1))   \n",
    "        out = self.up5(d4)                           \n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:56:14.835395Z",
     "iopub.status.busy": "2025-04-23T18:56:14.834709Z",
     "iopub.status.idle": "2025-04-23T18:56:15.334090Z",
     "shell.execute_reply": "2025-04-23T18:56:15.333573Z",
     "shell.execute_reply.started": "2025-04-23T18:56:14.835369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create model and move to CUDA, using MSE loss and Adam Optimizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetUNetColor().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:56:34.846720Z",
     "iopub.status.busy": "2025-04-23T18:56:34.846128Z",
     "iopub.status.idle": "2025-04-23T20:24:44.870823Z",
     "shell.execute_reply": "2025-04-23T20:24:44.869710Z",
     "shell.execute_reply.started": "2025-04-23T18:56:34.846693Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training section with L and ab\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for L, ab in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        L, ab = L.to(device), ab.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_ab = model(L)\n",
    "        loss = criterion(output_ab, ab)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    checkpoint_path = f\"/kaggle/working/resnet_colorization_model_epoch_{epoch+1}.pth\"\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f\"Model saved to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T20:34:47.937794Z",
     "iopub.status.busy": "2025-04-23T20:34:47.937054Z",
     "iopub.status.idle": "2025-04-23T20:34:47.944647Z",
     "shell.execute_reply": "2025-04-23T20:34:47.943907Z",
     "shell.execute_reply.started": "2025-04-23T20:34:47.937770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To colorize single image with model in evaluation mode\n",
    "\n",
    "def colorize_single_image(model, image_path, device):\n",
    "    model.eval()\n",
    "\n",
    "    img = Image.open(image_path).convert(\"RGB\").resize((256, 256))\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Convert to LAB and extract L channel\n",
    "    lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "    L = lab[:, :, 0] / 255.0 \n",
    "\n",
    "    L_tensor = torch.from_numpy(L).unsqueeze(0).unsqueeze(0).float().to(device) \n",
    "    with torch.no_grad():\n",
    "        ab_pred = model(L_tensor)[0].cpu().numpy().transpose(1, 2, 0) * 128.0\n",
    "\n",
    "    L_img = L * 255.0\n",
    "    lab_pred = np.zeros((256, 256, 3), dtype=np.float32)\n",
    "    lab_pred[:, :, 0] = L_img\n",
    "    lab_pred[:, :, 1:] = ab_pred\n",
    "    rgb_pred = cv2.cvtColor(lab_pred.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(rgb_pred)\n",
    "    plt.title(\"Colorized Output\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T20:35:08.372323Z",
     "iopub.status.busy": "2025-04-23T20:35:08.371649Z",
     "iopub.status.idle": "2025-04-23T20:35:08.669256Z",
     "shell.execute_reply": "2025-04-23T20:35:08.668632Z",
     "shell.execute_reply.started": "2025-04-23T20:35:08.372298Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To test the hybrid model performance on different images\n",
    "\n",
    "image_path = \"/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/test/ILSVRC2012_test_00000004.JPEG\"  # Upload your own image to input folder\n",
    "colorize_single_image(model, image_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 4225553,
     "sourceId": 6799,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
