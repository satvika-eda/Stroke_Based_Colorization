{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Freeform Colorization with Hybrid Resnet-UNet</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# List of specific ImageNet class IDs to include in the subset\n",
    "subset_class_ids = [\n",
    "    \"n01440764\", \"n01491361\", \"n01498041\", \"n01514859\", \"n01530575\", \"n01616318\", \"n01622779\", \"n01629819\", \"n01641577\", \"n01664065\",\n",
    "    \"n01729322\", \"n01734418\", \"n01742172\", \"n01774750\", \"n01795545\", \"n01806143\", \"n01833805\", \"n01882714\", \"n01914609\", \"n01945685\",\n",
    "    \"n01978455\", \"n01985128\", \"n02002556\", \"n02006656\", \"n02011460\", \"n02058221\", \"n02071294\", \"n02085782\", \"n02088466\", \"n02099601\",\n",
    "    \"n02100583\", \"n02104029\", \"n02106550\", \"n02110063\", \"n02110958\", \"n02112137\", \"n02113023\", \"n02113799\", \"n02123045\", \"n02128757\",\n",
    "    \"n02132136\", \"n02165456\", \"n02190166\", \"n02206856\", \"n02226429\", \"n02233338\", \"n02256656\", \"n02279972\", \"n02317335\", \"n02346627\",\n",
    "    \"n02364673\", \"n02391049\", \"n02395406\", \"n02403003\", \"n02412080\", \"n02415577\", \"n02423022\", \"n02437312\", \"n02480495\", \"n02504458\",\n",
    "    \"n02509815\", \"n02640242\", \"n02692877\", \"n02708093\", \"n02786058\", \"n02795169\", \"n02814533\", \"n02823428\", \"n02837789\", \"n02879718\",\n",
    "    \"n02951358\", \"n02966193\", \"n03014705\", \"n03047690\", \"n03085013\", \"n03100240\", \"n03126707\", \"n03160309\", \"n03179701\", \"n03255030\",\n",
    "    \"n03272010\", \"n03314780\", \"n03379051\", \"n03417042\", \"n03424325\", \"n03444034\", \"n03478589\", \"n03494278\", \"n03584829\", \"n03633091\",\n",
    "    \"n03666591\", \"n03770439\", \"n03793489\", \"n03814639\", \"n03888257\", \"n03933933\", \"n03976657\", \"n04037443\", \"n04118538\", \"n04552348\"\n",
    "]\n",
    "\n",
    "# Directories\n",
    "imagenet_train_dir = \"/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train\"\n",
    "subset_dir = \"/kaggle/working/imagenet_subset/train\"\n",
    "\n",
    "# Create target root directory\n",
    "os.makedirs(subset_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through specified class IDs\n",
    "for class_id in subset_class_ids:\n",
    "    src_class_dir = os.path.join(imagenet_train_dir, class_id)\n",
    "    dst_class_dir = os.path.join(subset_dir, class_id)\n",
    "    os.makedirs(dst_class_dir, exist_ok=True)\n",
    "    \n",
    "    # List all images\n",
    "    images = sorted(os.listdir(src_class_dir))\n",
    "    \n",
    "    # Copy all images\n",
    "    for img_name in images:\n",
    "        src_img_path = os.path.join(src_class_dir, img_name)\n",
    "        dst_img_path = os.path.join(dst_class_dir, img_name)\n",
    "        shutil.copyfile(src_img_path, dst_img_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:55:31.001358Z",
     "iopub.status.busy": "2025-04-23T18:55:31.001106Z",
     "iopub.status.idle": "2025-04-23T18:55:35.140207Z",
     "shell.execute_reply": "2025-04-23T18:55:35.139654Z",
     "shell.execute_reply.started": "2025-04-23T18:55:31.001339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader# from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class ImageNetColorizationDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_paths = []\n",
    "        for subdir, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.JPEG') or file.endswith('.jpg'):\n",
    "                    self.image_paths.append(os.path.join(subdir, file))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\").resize((256, 256))\n",
    "            img = np.array(img)\n",
    "    \n",
    "            lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "            L = lab[:, :, 0] / 255.0\n",
    "            ab = lab[:, :, 1:] / 128.0\n",
    "    \n",
    "            L = torch.from_numpy(L).unsqueeze(0).float()        # [1, H, W]\n",
    "            ab = torch.from_numpy(ab.transpose((2, 0, 1))).float()  # [2, H, W]\n",
    "    \n",
    "            return L, ab\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {img_path}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:55:35.141524Z",
     "iopub.status.busy": "2025-04-23T18:55:35.141217Z",
     "iopub.status.idle": "2025-04-23T18:55:39.901677Z",
     "shell.execute_reply": "2025-04-23T18:55:39.900992Z",
     "shell.execute_reply.started": "2025-04-23T18:55:35.141501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "imagenet_dataset = ImageNetColorizationDataset('/kaggle/working/imagenet_subset/train', transform=transform)\n",
    "train_loader = DataLoader(\n",
    "    imagenet_dataset,\n",
    "    batch_size=32,                  # Increase batch size if memory allows\n",
    "    shuffle=True,\n",
    "    num_workers=8,                  # Increase workers (rule: 4 * num_GPUs)\n",
    "    pin_memory=True,                # Keep this for GPU transfer efficiency\n",
    "    prefetch_factor=2,              # Prefetch batches\n",
    "    persistent_workers=True,        # Keep workers alive between epochs\n",
    "    drop_last=True                  # Slightly faster by dropping incomplete batches\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:55:43.347594Z",
     "iopub.status.busy": "2025-04-23T18:55:43.347002Z",
     "iopub.status.idle": "2025-04-23T18:55:43.662673Z",
     "shell.execute_reply": "2025-04-23T18:55:43.662114Z",
     "shell.execute_reply.started": "2025-04-23T18:55:43.347570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def rgb_to_lab(img_rgb):\n",
    "    img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
    "    L, a, b = cv2.split(img_lab)\n",
    "    return L / 255.0, a / 128.0, b / 128.0  # normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:55:44.587090Z",
     "iopub.status.busy": "2025-04-23T18:55:44.586810Z",
     "iopub.status.idle": "2025-04-23T18:55:44.596206Z",
     "shell.execute_reply": "2025-04-23T18:55:44.595570Z",
     "shell.execute_reply.started": "2025-04-23T18:55:44.587068Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResNetUNetColor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetUNetColor, self).__init__()\n",
    "\n",
    "        # Load pretrained ResNet18\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "        # Use only first conv block (accepts RGB), we’ll modify to accept 1-channel input\n",
    "        self.input_conv = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Extract ResNet layers for encoder\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "\n",
    "        self.layer1 = resnet.layer1  # [64, 64, 64]\n",
    "        self.layer2 = resnet.layer2  # [128, 32, 32]\n",
    "        self.layer3 = resnet.layer3  # [256, 16, 16]\n",
    "        self.layer4 = resnet.layer4  # [512, 8, 8]\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = self.up_block(512, 256)\n",
    "        self.up2 = self.up_block(512, 128)  # skip from layer3\n",
    "        self.up3 = self.up_block(256, 64)   # skip from layer2\n",
    "        self.up4 = self.up_block(128, 64)   # skip from layer1\n",
    "        self.up5 = nn.Sequential(           # final upsampling to 256×256\n",
    "            nn.ConvTranspose2d(64, 32, 2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 2, kernel_size=1)  # Output ab channels\n",
    "        )\n",
    "\n",
    "    def up_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.relu(self.bn1(self.input_conv(x)))  # [64, 128, 128]\n",
    "        x2 = self.layer1(self.maxpool(x1))            # [64, 64, 64]\n",
    "        x3 = self.layer2(x2)                          # [128, 32, 32]\n",
    "        x4 = self.layer3(x3)                          # [256, 16, 16]\n",
    "        x5 = self.layer4(x4)                          # [512, 8, 8]\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        d1 = self.up1(x5)                             # [256, 16, 16]\n",
    "        d2 = self.up2(torch.cat([d1, x4], dim=1))     # [128, 32, 32]\n",
    "        d3 = self.up3(torch.cat([d2, x3], dim=1))     # [64, 64, 64]\n",
    "        d4 = self.up4(torch.cat([d3, x2], dim=1))     # [64, 128, 128]\n",
    "        out = self.up5(d4)                            # [2, 256, 256]\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:56:14.835395Z",
     "iopub.status.busy": "2025-04-23T18:56:14.834709Z",
     "iopub.status.idle": "2025-04-23T18:56:15.334090Z",
     "shell.execute_reply": "2025-04-23T18:56:15.333573Z",
     "shell.execute_reply.started": "2025-04-23T18:56:14.835369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetUNetColor().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# 3. Now define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:56:34.846720Z",
     "iopub.status.busy": "2025-04-23T18:56:34.846128Z",
     "iopub.status.idle": "2025-04-23T20:24:44.870823Z",
     "shell.execute_reply": "2025-04-23T20:24:44.869710Z",
     "shell.execute_reply.started": "2025-04-23T18:56:34.846693Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for L, ab in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        L, ab = L.to(device), ab.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_ab = model(L)\n",
    "        loss = criterion(output_ab, ab)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    checkpoint_path = f\"/kaggle/working/resnet_colorization_model_epoch_{epoch+1}.pth\"\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f\"Model saved to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T20:26:08.550163Z",
     "iopub.status.busy": "2025-04-23T20:26:08.549200Z",
     "iopub.status.idle": "2025-04-23T20:26:08.561044Z",
     "shell.execute_reply": "2025-04-23T20:26:08.560314Z",
     "shell.execute_reply.started": "2025-04-23T20:26:08.550125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "def visualize_colorization(model, dataloader, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for L, ab in dataloader:\n",
    "            L, ab = L.to(device), ab.to(device)\n",
    "            output_ab = model(L)\n",
    "\n",
    "            # Get first sample in batch\n",
    "            L_img = L[0].cpu().numpy()[0] * 255.0  # [256, 256]\n",
    "            ab_gt = ab[0].cpu().numpy().transpose(1, 2, 0) * 128.0  # [256, 256, 2]\n",
    "            ab_pred = output_ab[0].cpu().numpy().transpose(1, 2, 0) * 128.0\n",
    "\n",
    "            # Construct LAB images\n",
    "            lab_gt = np.zeros((256, 256, 3), dtype=np.float32)\n",
    "            lab_pred = np.zeros((256, 256, 3), dtype=np.float32)\n",
    "            lab_gt[:, :, 0] = L_img\n",
    "            lab_gt[:, :, 1:] = ab_gt\n",
    "            lab_pred[:, :, 0] = L_img\n",
    "            lab_pred[:, :, 1:] = ab_pred\n",
    "\n",
    "            # Convert LAB to RGB\n",
    "            rgb_gt = cv2.cvtColor(lab_gt.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "            rgb_pred = cv2.cvtColor(lab_pred.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "            # Grayscale visualization\n",
    "            gray_img = cv2.cvtColor(rgb_gt, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(rgb_gt)\n",
    "            plt.title(\"Original\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(gray_img, cmap='gray')\n",
    "            plt.title(\"Input Grayscale\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(rgb_pred)\n",
    "            plt.title(\"Reconstructed\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            break  # Show only one batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T20:33:12.471840Z",
     "iopub.status.busy": "2025-04-23T20:33:12.471201Z",
     "iopub.status.idle": "2025-04-23T20:33:14.798117Z",
     "shell.execute_reply": "2025-04-23T20:33:14.797295Z",
     "shell.execute_reply.started": "2025-04-23T20:33:12.471819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "visualize_colorization(model, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T20:34:47.937794Z",
     "iopub.status.busy": "2025-04-23T20:34:47.937054Z",
     "iopub.status.idle": "2025-04-23T20:34:47.944647Z",
     "shell.execute_reply": "2025-04-23T20:34:47.943907Z",
     "shell.execute_reply.started": "2025-04-23T20:34:47.937770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def colorize_single_image(model, image_path, device):\n",
    "    model.eval()\n",
    "\n",
    "    # Load and resize image\n",
    "    img = Image.open(image_path).convert(\"RGB\").resize((256, 256))\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Convert to LAB and extract L channel\n",
    "    lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "    L = lab[:, :, 0] / 255.0  # Normalize L channel\n",
    "\n",
    "    # Convert to tensor\n",
    "    L_tensor = torch.from_numpy(L).unsqueeze(0).unsqueeze(0).float().to(device)  # [1, 1, 256, 256]\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        ab_pred = model(L_tensor)[0].cpu().numpy().transpose(1, 2, 0) * 128.0\n",
    "\n",
    "    # Reconstruct LAB image and convert to RGB\n",
    "    L_img = L * 255.0\n",
    "    lab_pred = np.zeros((256, 256, 3), dtype=np.float32)\n",
    "    lab_pred[:, :, 0] = L_img\n",
    "    lab_pred[:, :, 1:] = ab_pred\n",
    "    rgb_pred = cv2.cvtColor(lab_pred.astype(np.uint8), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    # Show result\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(rgb_pred)\n",
    "    plt.title(\"Colorized Output\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T20:35:08.372323Z",
     "iopub.status.busy": "2025-04-23T20:35:08.371649Z",
     "iopub.status.idle": "2025-04-23T20:35:08.669256Z",
     "shell.execute_reply": "2025-04-23T20:35:08.668632Z",
     "shell.execute_reply.started": "2025-04-23T20:35:08.372298Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/test/ILSVRC2012_test_00000004.JPEG\"  # Upload your own image to input folder\n",
    "colorize_single_image(model, image_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 4225553,
     "sourceId": 6799,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
